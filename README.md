
# DE Interview Assignment Solutions

This repository contains solutions to the Data Engineering interview assignments provided. Below are the details of each task and the respective solution directories:

## Table of Contents
1. [Oracle 12c to GCP BigQuery Data Pipeline](#oracle-12c-to-gcp-bigquery-data-pipeline)
2. [Custom ML Model Deployment on GCP](#custom-ml-model-deployment-on-gcp)
3. [Python Application for Category-based GMV Analysis](#python-application-for-category-based-gmv-analysis)
4. [Real-time Event Aggregation for E-commerce](#real-time-event-aggregation-for-e-commerce)

---

### Oracle 12c to GCP BigQuery Data Pipeline
You are asked to construct a data pipeline between on-premise Oracle 12c data warehouse and Google Cloud Platform (GCP) BigQuery data warehouse. The solution primarily utilizes GCP tools and Python scripting. Data integration tools are not used.
- **Solution Directory**: [assignment1](./assignment1/)

---

### Custom ML Model Deployment on GCP
This task involves deploying a custom ML model data architecture onto GCP. The model will operate online, and the challenge is to establish all the necessary components and a complete pipeline.
- **Solution Directory**: [assignment2](./assignment2/)

---

### Python Application for Category-based GMV Analysis
The objective is to develop a Python application that satisfies the given requirement: For a particular category, which 5 sellers that aren't designated as key sellers have the highest Gross Merchandise Volume (GMV) in that category?
- **Solution Directory**: [assignment3](./assignment3/)

---

### Real-time Event Aggregation for E-commerce
The goal is to aggregate continuously generated events in real-time for our e-commerce website. These events, which are all clickstream events, need to be pushed to an associated Kafka topic.
- **Solution Directory**: [assignment4](./assignment4/)

---
